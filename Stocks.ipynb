{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the future price of Apple Company using LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the reqd libraries:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Dense,InputLayer\n",
    "\n",
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "!pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the Style for plots\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the data from yfinance:\n",
    "### AAPL is the short form for Apple.\n",
    "data = yf.download(\"AAPL\", start=\"2005-01-01\", end=\"2020-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly it represents time series data because indices are of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking for Missing Values:\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualising the initial distribution of the data to check if it makes sense:\n",
    "### Checking the Closing Price\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(16,16))\n",
    "\n",
    "ax[0].set_title(\"Closing Price History\")\n",
    "ax[0].plot(data['Close'])\n",
    "ax[0].set_xlabel(\"Data\")\n",
    "ax[0].set_ylabel(\"Closing Price in USD\")\n",
    "ax[0].legend()\n",
    "\n",
    "### Checking the Closing Price\n",
    "\n",
    "ax[1].set_title(\"Opening Price History\")\n",
    "ax[1].plot(data['Open'])\n",
    "ax[1].set_xlabel(\"Data\")\n",
    "ax[1].set_ylabel(\"Opening Price in USD\")\n",
    "ax[1].legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining the above plots into one:\n",
    "plt.figure(figsize=(16,7))\n",
    "\n",
    "plt.title(\"Closing Price History/Opening Price History\")\n",
    "plt.plot(data['Close'],\"b\")\n",
    "plt.plot(data['Open'],\"y\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Closing Price in USD\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zooming into one section, say dates between 2005 and 2007:\n",
    "\n",
    "mask1 = (data.index >= '2005-01-01') & (data.index <= '2007-01-01')\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(16,16))\n",
    "\n",
    "ax[0].set_title(\"Closing Price History/Opening Price History for the period 2005-2006\")\n",
    "ax[0].plot(data['Close'].loc[mask1],\"b\")\n",
    "ax[0].plot(data['Open'].loc[mask1],\"y\")\n",
    "ax[0].set_xlabel(\"Data\")\n",
    "ax[0].set_ylabel(\"Closing Price in USD\")\n",
    "ax[0].legend()\n",
    "\n",
    "### Zooming further into one section, say dates in 2005:\n",
    "mask2 = (data.index >= '2005-01-01') & (data.index <= '2006-01-01')\n",
    "\n",
    "ax[1].set_title(\"Closing Price History/Opening Price History for 2005\")\n",
    "ax[1].plot(data['Close'].loc[mask2],\"b\")\n",
    "ax[1].plot(data['Open'].loc[mask2],\"y\")\n",
    "ax[1].set_xlabel(\"Data\")\n",
    "ax[1].set_ylabel(\"Closing Price in USD\")\n",
    "ax[1].legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conducting the Forecasting on the \"Close\" price:\n",
    "df=data[\"Close\"]\n",
    "\n",
    "### LSTMs are very sensitive to the scale of the data. So I apply MinMaxScaler:\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df_scaled=scaler.fit_transform(np.array(df).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting dataset into train and test\n",
    "n=len(df_scaled)\n",
    "\n",
    "training_size=int(n*0.65)\n",
    "test_size=n-training_size\n",
    "\n",
    "train_data,test_data=df_scaled[0:training_size,:],df_scaled[training_size:n,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First five values of the training data\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reshape(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the **CRUX** of the data preparation step:\n",
    "\n",
    "Step 1. Choose the number of time steps(**t**). This controls the number of data points that are going to be used to predict \n",
    "the current data point.\n",
    "\n",
    "Step 2: Create the Dataset with t features and a target variable\n",
    "\n",
    "**NOTE**:Time steps(t) is an important hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(df,t):\n",
    "    n=len(df)\n",
    "    df=df.reshape(n)\n",
    "    output=[]\n",
    "    label=[]\n",
    "    for x in range(n-t-1):\n",
    "        output.append(list(df[x:x+t]))\n",
    "        label.append(df[x+t])\n",
    "    \n",
    "    return np.array(output),np.array(label)\n",
    "\n",
    "X_train,y_train=create_data(train_data,60)\n",
    "\n",
    "X_test,y_test=create_data(test_data,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Making: (Simple LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LSTM model is defined using the Tensorflow deep learning library. \n",
    "\n",
    "The model requires a three-dimensional input as:\n",
    "**[samples, time steps, features]**.\n",
    "\n",
    "Hence we reshape the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(X_train.shape[1],1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(16,5))\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].plot(model.history.history['loss'])\n",
    "ax[1].set_title(\"Test Loss\")\n",
    "ax[1].plot(model.history.history['val_loss'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the prediction and validating the predictions using performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=model.predict(X_train) \n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The RMSE is defined as:\n",
    "### math.sqrt(mean_squared_error(actual,predicted))\n",
    "\n",
    "### Train Error:\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))\n",
    "\n",
    "### Test Error:\n",
    "math.sqrt(mean_squared_error(y_test,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transforming the data back to its original scale:\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Error after back-scaling:\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))\n",
    "\n",
    "### Test Error after back-scaling:\n",
    "math.sqrt(mean_squared_error(y_test,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the predicted observations:\n",
    "\n",
    "# shift train predictions for plotting\n",
    "t=60\n",
    "trainPredictPlot = np.empty_like(df_scaled)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[t:len(train_predict)+t, :] = train_predict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(df_scaled)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(t*2)+1:len(df_scaled)-1, :] = test_predict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Overlap of Original Dataset and Predictions\")\n",
    "plt.plot(scaler.inverse_transform(df_scaled),label=\"Original Data\")\n",
    "plt.plot(trainPredictPlot,label=\"Predicted Train\")\n",
    "plt.plot(testPredictPlot,label=\"Predicted Test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Above Plot, it is clearly visible that our model is has performed considerably good in retracing the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For forecasting the next 30 days, we need to consider the last 60 data points present in the original test data i.e.**test_data** variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=test_data[test_data.shape[0]-60:].reshape(1,-1)\n",
    "x_input.shape\n",
    "\n",
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist()\n",
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Forecast for next 30 Days:\n",
    "lst_output=[]\n",
    "n_steps=60\n",
    "i=0\n",
    "while(i<30):\n",
    "    \n",
    "    if(len(temp_input)>60): ## after first iteration, temp_input will have size of 61\n",
    "        \n",
    "        x_input=np.array(temp_input[1:])\n",
    "       \n",
    "        x_input = x_input.reshape(1,-1).reshape((1, n_steps, 1))\n",
    "        \n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        \n",
    "        temp_input.extend(yhat[0].tolist())  ### Adding prediction to the temp_input, which will serve as test data for next iteration\n",
    "        temp_input=temp_input[1:]   ### Ignores the first value, as it is not required for next price's prediction.\n",
    "        \n",
    "        lst_output.extend(yhat.tolist())  ### Appends the cost\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "    else:  ### Runs initially as x_input will be of length 60 initially:\n",
    "        \n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,61)\n",
    "day_pred=np.arange(61,91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(day_new,scaler.inverse_transform(df_scaled[df_scaled.shape[0]-60:]))\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3eff57f1b29dfdd788faddb90ebd9222db114d636e87b8fde724656933d5975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
